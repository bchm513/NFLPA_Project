{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a989d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merged_data = pd.read_csv('../data_prep/data/left_merged_data.csv')\n",
    "right_merged_data = pd.read_csv('../data_prep/data/right_merged_data.csv')\n",
    "inner_merged_data = pd.read_csv('../data_prep/data/inner_merged_data.csv')\n",
    "outer_merged_data = pd.read_csv('../data_prep/data/outer_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b80a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_merged_data\n",
    "# right_merged_data\n",
    "# inner_merged_data\n",
    "# outer_merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a052e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in left_merged_data.columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6a8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_columns(df):\n",
    "    \"\"\"\n",
    "    Remove duplicate columns from DataFrame as specified.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with specified duplicate columns removed\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # List of all columns to remove\n",
    "    columns_to_remove = [\n",
    "        # Auto-generated indices\n",
    "        'Unnamed: 0',\n",
    "        'index',\n",
    "        \n",
    "        # Duplicate stats (keeping _x versions, removing _y versions)\n",
    "        'pass_cmp_y',\n",
    "        'rush_att_y',\n",
    "        'rush_yds_y', \n",
    "        'rush_td_y',\n",
    "        'targets_y',\n",
    "        'rec_y',\n",
    "        'rec_yds_y',\n",
    "        'rec_td_y',\n",
    "        'def_int_y',\n",
    "        'sacks_y',\n",
    "        'tackles_combined_y',\n",
    "        \n",
    "        # Duplicate without suffix\n",
    "        ' pass_att',  # with leading space\n",
    "        \n",
    "        # Keep elevation, remove stadium (or vice versa - choose one)\n",
    "        'team_home_stadium',  # Remove this, keep team_home_elevation\n",
    "    ]\n",
    "    \n",
    "    # Remove the columns\n",
    "    df_clean = df_clean.drop(columns=columns_to_remove, errors='ignore')\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d17ee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(df):\n",
    "    # Method 1: Using pandas to_datetime with custom format\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%A %b %d %Y', errors='coerce')\n",
    "\n",
    "    print(\"Sample conversions:\")\n",
    "    print(df['date'].head(10))\n",
    "    print(f\"\\nNumber of failed conversions: {df['date'].isna().sum()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e48ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample conversions:\n",
      "0   2016-09-08\n",
      "1   2016-09-08\n",
      "2   2016-09-08\n",
      "3   2016-09-08\n",
      "4   2016-09-08\n",
      "5   2016-09-08\n",
      "6   2016-09-08\n",
      "7   2016-09-08\n",
      "8   2016-09-08\n",
      "9   2016-09-08\n",
      "Name: date, dtype: datetime64[ns]\n",
      "\n",
      "Number of failed conversions: 0\n",
      "Sample conversions:\n",
      "0   2016-09-08\n",
      "1   2016-09-08\n",
      "2   2016-09-08\n",
      "3   2016-09-08\n",
      "4   2016-09-08\n",
      "5   2016-09-08\n",
      "6   2016-09-08\n",
      "7   2016-09-08\n",
      "8   2016-09-08\n",
      "9   2016-09-08\n",
      "Name: date, dtype: datetime64[ns]\n",
      "\n",
      "Number of failed conversions: 0\n",
      "Sample conversions:\n",
      "0   2016-09-08\n",
      "1   2016-09-08\n",
      "2   2016-09-08\n",
      "3   2016-09-08\n",
      "4   2016-09-08\n",
      "5   2016-09-08\n",
      "6   2016-09-08\n",
      "7   2016-09-11\n",
      "8   2016-09-11\n",
      "9   2016-09-11\n",
      "Name: date, dtype: datetime64[ns]\n",
      "\n",
      "Number of failed conversions: 0\n",
      "Sample conversions:\n",
      "0   2023-12-11\n",
      "1   2021-12-13\n",
      "2   2023-12-25\n",
      "3   2016-12-26\n",
      "4   2018-12-03\n",
      "5   2022-01-17\n",
      "6   2021-11-15\n",
      "7   2016-11-21\n",
      "8   2020-11-23\n",
      "9   2025-11-24\n",
      "Name: date, dtype: datetime64[ns]\n",
      "\n",
      "Number of failed conversions: 0\n"
     ]
    }
   ],
   "source": [
    "updated_left_merged_data = to_datetime(left_merged_data)\n",
    "updated_right_merged_data = to_datetime(right_merged_data)\n",
    "updated_inner_merged_data = to_datetime(inner_merged_data)\n",
    "updated_outer_merged_data = to_datetime(outer_merged_data)\n",
    "\n",
    "clean_left_merged_data = remove_duplicate_columns(updated_left_merged_data)\n",
    "clean_right_merged_data = remove_duplicate_columns(updated_right_merged_data)\n",
    "clean_inner_merged_data = remove_duplicate_columns(updated_inner_merged_data)\n",
    "clean_outer_merged_data = remove_duplicate_columns(updated_outer_merged_data)\n",
    "\n",
    "org_left_merged_data = clean_left_merged_data.sort_values(['player_name','date'])\n",
    "org_right_merged_data = clean_right_merged_data.sort_values(['player_name','date'])\n",
    "org_inner_merged_data = clean_inner_merged_data.sort_values(['player_name','date'])\n",
    "org_outer_merged_data = clean_outer_merged_data.sort_values(['player_name','date'])\n",
    "\n",
    "# print(len(right_merged_data.columns))\n",
    "# print(len(clean_right_merged_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e77021",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_left_merged_data.to_csv('clean_data/clean_left_merged_data.csv')\n",
    "org_outer_merged_data.to_csv('clean_data/clean_outer_merged_data.csv')\n",
    "org_inner_merged_data.to_csv('clean_data/clean_inner_merged_data.csv')\n",
    "org_right_merged_data.to_csv('clean_data/clean_right_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471ef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bchm5\\AppData\\Local\\Temp\\ipykernel_30396\\1442244047.py:1: DtypeWarning: Columns (84,86,92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_outer_merged_data = pd.read_csv('clean_data/clean_outer_merged_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>player_name</th>\n",
       "      <th>date</th>\n",
       "      <th>player_team</th>\n",
       "      <th>position</th>\n",
       "      <th>injury_lcoation</th>\n",
       "      <th>practice_status</th>\n",
       "      <th>game_status\\t\\t</th>\n",
       "      <th>game_id</th>\n",
       "      <th>snap_count</th>\n",
       "      <th>...</th>\n",
       "      <th>game_tz_difference</th>\n",
       "      <th>travel_direction</th>\n",
       "      <th>tz_diff_magnitude</th>\n",
       "      <th>travel_magnitude</th>\n",
       "      <th>is_long_travel</th>\n",
       "      <th>travel_description</th>\n",
       "      <th>game_stadium_elevation</th>\n",
       "      <th>team_home_elevation</th>\n",
       "      <th>elevation_difference_m</th>\n",
       "      <th>elevation_difference_abs_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288109</th>\n",
       "      <td>288111</td>\n",
       "      <td>Trey Taylor</td>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411240rai</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>609.6</td>\n",
       "      <td>609.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288110</th>\n",
       "      <td>288105</td>\n",
       "      <td>Trey Taylor</td>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411290kan</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>east</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2_hr</td>\n",
       "      <td>False</td>\n",
       "      <td>travel_east_2_hours</td>\n",
       "      <td>274.3</td>\n",
       "      <td>609.6</td>\n",
       "      <td>-335.3</td>\n",
       "      <td>335.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288111</th>\n",
       "      <td>288109</td>\n",
       "      <td>Trey Taylor</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202412080tam</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>east</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3_hr</td>\n",
       "      <td>True</td>\n",
       "      <td>travel_east_3_hours</td>\n",
       "      <td>8.8</td>\n",
       "      <td>609.6</td>\n",
       "      <td>-600.8</td>\n",
       "      <td>600.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288112</th>\n",
       "      <td>288106</td>\n",
       "      <td>Trey Taylor</td>\n",
       "      <td>2024-12-16</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202412160rai</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>609.6</td>\n",
       "      <td>609.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288113</th>\n",
       "      <td>288107</td>\n",
       "      <td>Trey Taylor</td>\n",
       "      <td>2024-12-22</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202412220rai</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>609.6</td>\n",
       "      <td>609.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307667</th>\n",
       "      <td>307635</td>\n",
       "      <td>Zyon McCollum</td>\n",
       "      <td>2025-11-16</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202511160buf</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>183.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>174.7</td>\n",
       "      <td>174.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307668</th>\n",
       "      <td>307637</td>\n",
       "      <td>Zyon McCollum</td>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202511230ram</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>west</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3_hr</td>\n",
       "      <td>True</td>\n",
       "      <td>travel_west_3_hours</td>\n",
       "      <td>36.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>27.8</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307669</th>\n",
       "      <td>307641</td>\n",
       "      <td>Zyon McCollum</td>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202511300tam</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307670</th>\n",
       "      <td>307624</td>\n",
       "      <td>Zyon McCollum</td>\n",
       "      <td>2025-12-07</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202512070tam</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307671</th>\n",
       "      <td>307668</td>\n",
       "      <td>Zyon McCollum</td>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202512110tam</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home</td>\n",
       "      <td>False</td>\n",
       "      <td>home_game</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19563 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    player_name        date player_team position  \\\n",
       "288109      288111    Trey Taylor  2024-11-24     Raiders      NaN   \n",
       "288110      288105    Trey Taylor  2024-11-29     Raiders      NaN   \n",
       "288111      288109    Trey Taylor  2024-12-08     Raiders      NaN   \n",
       "288112      288106    Trey Taylor  2024-12-16     Raiders      NaN   \n",
       "288113      288107    Trey Taylor  2024-12-22     Raiders      NaN   \n",
       "...            ...            ...         ...         ...      ...   \n",
       "307667      307635  Zyon McCollum  2025-11-16  Buccaneers      NaN   \n",
       "307668      307637  Zyon McCollum  2025-11-23  Buccaneers      NaN   \n",
       "307669      307641  Zyon McCollum  2025-11-30  Buccaneers      NaN   \n",
       "307670      307624  Zyon McCollum  2025-12-07  Buccaneers      NaN   \n",
       "307671      307668  Zyon McCollum  2025-12-11  Buccaneers      NaN   \n",
       "\n",
       "       injury_lcoation practice_status game_status\\t\\t       game_id  \\\n",
       "288109             NaN             NaN             NaN  202411240rai   \n",
       "288110             NaN             NaN             NaN  202411290kan   \n",
       "288111             NaN             NaN             NaN  202412080tam   \n",
       "288112             NaN             NaN             NaN  202412160rai   \n",
       "288113             NaN             NaN             NaN  202412220rai   \n",
       "...                ...             ...             ...           ...   \n",
       "307667             NaN             NaN             NaN  202511160buf   \n",
       "307668             NaN             NaN             NaN  202511230ram   \n",
       "307669             NaN             NaN             NaN  202511300tam   \n",
       "307670             NaN             NaN             NaN  202512070tam   \n",
       "307671             NaN             NaN             NaN  202512110tam   \n",
       "\n",
       "        snap_count  ... game_tz_difference travel_direction tz_diff_magnitude  \\\n",
       "288109        15.0  ...                0.0             home               0.0   \n",
       "288110        13.0  ...                2.0             east               2.0   \n",
       "288111        16.0  ...                3.0             east               3.0   \n",
       "288112        16.0  ...                0.0             home               0.0   \n",
       "288113        16.0  ...                0.0             home               0.0   \n",
       "...            ...  ...                ...              ...               ...   \n",
       "307667        63.0  ...                0.0             home               0.0   \n",
       "307668        63.0  ...               -3.0             west               3.0   \n",
       "307669        65.0  ...                0.0             home               0.0   \n",
       "307670        64.0  ...                0.0             home               0.0   \n",
       "307671        26.0  ...                0.0             home               0.0   \n",
       "\n",
       "       travel_magnitude is_long_travel   travel_description  \\\n",
       "288109             home          False            home_game   \n",
       "288110             2_hr          False  travel_east_2_hours   \n",
       "288111             3_hr           True  travel_east_3_hours   \n",
       "288112             home          False            home_game   \n",
       "288113             home          False            home_game   \n",
       "...                 ...            ...                  ...   \n",
       "307667             home          False            home_game   \n",
       "307668             3_hr           True  travel_west_3_hours   \n",
       "307669             home          False            home_game   \n",
       "307670             home          False            home_game   \n",
       "307671             home          False            home_game   \n",
       "\n",
       "        game_stadium_elevation team_home_elevation elevation_difference_m  \\\n",
       "288109                   609.6               609.6                    0.0   \n",
       "288110                   274.3               609.6                 -335.3   \n",
       "288111                     8.8               609.6                 -600.8   \n",
       "288112                   609.6               609.6                    0.0   \n",
       "288113                   609.6               609.6                    0.0   \n",
       "...                        ...                 ...                    ...   \n",
       "307667                   183.5                 8.8                  174.7   \n",
       "307668                    36.6                 8.8                   27.8   \n",
       "307669                     8.8                 8.8                    0.0   \n",
       "307670                     8.8                 8.8                    0.0   \n",
       "307671                     8.8                 8.8                    0.0   \n",
       "\n",
       "       elevation_difference_abs_m  \n",
       "288109                        0.0  \n",
       "288110                      335.3  \n",
       "288111                      600.8  \n",
       "288112                        0.0  \n",
       "288113                        0.0  \n",
       "...                           ...  \n",
       "307667                      174.7  \n",
       "307668                       27.8  \n",
       "307669                        0.0  \n",
       "307670                        0.0  \n",
       "307671                        0.0  \n",
       "\n",
       "[19563 rows x 145 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outer_merged_data = pd.read_csv('clean_data/clean_outer_merged_data.csv')\n",
    "\n",
    "finish_the_rest = final_outer_merged_data.iloc[288109:].copy()\n",
    "# finish_the_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13474baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6020\n"
     ]
    }
   ],
   "source": [
    "# clean_left_merged_data['injury_lcoation'].unique()\n",
    "print(len(final_outer_merged_data['player_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a11059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(df):\n",
    "\n",
    "    # Helper function to safely convert to numeric\n",
    "    def safe_numeric(series):\n",
    "        \"\"\"Convert series to numeric, coerce errors to NaN\"\"\"\n",
    "        return pd.to_numeric(series, errors='coerce')\n",
    "    \n",
    "    # Columns to group by for injury context\n",
    "    groupby_cols = [\"player_name\", \"date\", \"position\",\n",
    "                    \"injury_lcoation\", \"practice_status\", \"game_status\t\t\"]\n",
    "    \n",
    "    # Environment columns for \"before injury\" analysis\n",
    "    environment_cols = [\n",
    "        \"weather_content\", \"surface\", \"temperature\", \"humidity\", \"wind\", \"roof\",\n",
    "        \"time_zone_offset\", \"is_international\", \"team_timezone_offset\", \n",
    "        \"team_timezone\", \"game_tz_difference\", \"travel_direction\", \n",
    "        \"tz_diff_magnitude\", \"travel_magnitude\", \"is_long_travel\", \n",
    "        \"travel_description\", \"game_stadium_elevation\", \"team_home_elevation\",\n",
    "        \"elevation_difference_m\", \"elevation_difference_abs_m\",\n",
    "        \"snap_count\"\n",
    "    ]\n",
    "    \n",
    "    # Production columns for \"after injury\" analysis  \n",
    "    production_cols = [\n",
    "        # Basic offensive stats\n",
    "        \"pass_cmp_x\", \"pass_att\", \"pass_yds\", \"pass_td\", \"pass_int\", \n",
    "        \"pass_sacked_x\", \"pass_sacked_yds\", \"pass_long\", \"pass_rating\",\n",
    "        \"rush_att_x\", \"rush_yds_x\", \"rush_td_x\", \"rush_long\",\n",
    "        \"targets_x\", \"rec_x\", \"rec_yds_x\", \"rec_td_x\", \"rec_long\",\n",
    "        \"fumbles\", \"fumbles_lost\",\n",
    "        \n",
    "        # Defensive stats\n",
    "        \"def_int_x\", \"def_int_yds\", \"def_int_td\", \"def_int_long\", \"pass_defended\",\n",
    "        \"sacks_x\", \"tackles_combined_x\", \"tackles_solo\", \"tackles_assists\", \n",
    "        \"tackles_loss\", \"qb_hits\",\n",
    "        \"fumbles_rec\", \"fumbles_rec_yds\", \"fumbles_rec_td\", \"fumbles_forced\",\n",
    "        \n",
    "        # Special teams\n",
    "        \"xpm\", \"xpa\", \"fgm\", \"fga\",\n",
    "        \"punt\", \"punt_yds\", \"punt_yds_per_punt\", \"punt_long\",\n",
    "        \"kick_ret\", \"kick_ret_yds\", \"kick_ret_yds_per_ret\", \"kick_ret_td\", \"kick_ret_long\",\n",
    "        \"punt_ret\", \"punt_ret_yds\", \"punt_ret_yds_per_ret\", \"punt_ret_td\", \"punt_ret_long\",\n",
    "        \n",
    "        # Advanced offensive stats\n",
    "        \"pass_first_down\", \"pass_first_down_pct\", \"pass_target_yds\", \"pass_tgt_yds_per_att\",\n",
    "        \"pass_air_yds\", \"pass_air_yds_per_cmp\", \"pass_air_yds_per_att\",\n",
    "        \"pass_yac\", \"pass_yac_per_cmp\", \"pass_drops\", \"pass_drop_pct\",\n",
    "        \"pass_poor_throws\", \"pass_poor_throw_pct\", \"pass_sacked_y\", \"pass_blitzed\", \"pass_hurried\",\n",
    "        \"pass_hits\", \"pass_pressured\", \"pass_pressured_pct\", \"rush_scrambles\", \"rush_scrambles_yds_per_att\",\n",
    "        \"rush_first_down\", \"rush_yds_before_contact\", \"rush_yds_bc_per_rush\", \"rush_yac\", \"rush_yac_per_rush\",\n",
    "        \"rush_broken_tackles\", \"rush_broken_tackles_per_rush\",\n",
    "        \"rec_first_down\", \"rec_air_yds\", \"rec_air_yds_per_rec\", \"rec_yac\", \"rec_yac_per_rec\", \"rec_adot\",\n",
    "        \"rec_broken_tackles\", \"rec_broken_tackles_per_rec\", \"rec_drops\", \"rec_drop_pct\", \n",
    "        \"rec_target_int\", \"rec_pass_rating\",\n",
    "        \n",
    "        # Advanced defensive stats\n",
    "        \"def_targets\", \"def_cmp\", \"def_cmp_perc\", \"def_cmp_yds\", \"def_yds_per_cmp\",\n",
    "        \"def_yds_per_target\", \"def_cmp_td\", \"def_pass_rating\", \"def_tgt_yds_per_att\",\n",
    "        \"def_air_yds\", \"def_yac\",\n",
    "        \"blitzes\", \"qb_hurry\", \"qb_knockdown\", \"pressures\", \"tackles_missed\", \"tackles_missed_pct\",\n",
    "        \n",
    "        \"snap_count\"\n",
    "    ]\n",
    "    \n",
    "    # Filter to only include columns that exist in the dataframe\n",
    "    environment_cols = [col for col in environment_cols if col in df.columns]\n",
    "    production_cols = [col for col in production_cols if col in df.columns]\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for name in df['player_name'].unique():\n",
    "        count += 1\n",
    "        print(f\"Processing {name}... {count}/{len(final_outer_merged_data['player_name'].unique())}\")\n",
    "\n",
    "        current_name_df = df[df['player_name'] == name]\n",
    "        # print(current_name_df.head())\n",
    "\n",
    "        for index, row in current_name_df.iterrows():\n",
    "\n",
    "            group_row = []\n",
    "            for col in groupby_cols:\n",
    "                group_row.append(row[col])\n",
    "\n",
    "            # print(group_row)\n",
    "\n",
    "            # set injury date\n",
    "            injury_date = row['date']\n",
    "            # print(injury_date)\n",
    "\n",
    "            # Get previous games (before injury)\n",
    "            before_games = current_name_df[current_name_df['date'] < injury_date]\n",
    "            \n",
    "            # Get current and future games (after injury, including injury game)\n",
    "            after_games = current_name_df[current_name_df['date'] >= injury_date]\n",
    "            \n",
    "            # Get most recent previous game (the one right before injury)\n",
    "            prev_game = before_games.iloc[-1] if len(before_games) > 0 else pd.Series()\n",
    "\n",
    "            # print(before_games)\n",
    "            # print(after_games)\n",
    "            # print(prev_game)\n",
    "            \n",
    "            if len(before_games) > 0:\n",
    "\n",
    "                ##### environment variables\n",
    "                # get temperature\n",
    "                try:\n",
    "                    average_weather_before = before_games[\"temperature\"].mean()\n",
    "                except Exception:\n",
    "                    average_weather_before = np.nan\n",
    "                # get humidity\n",
    "                try:\n",
    "                    average_humidity_before = before_games[\"humidity\"].mean()\n",
    "                except Exception:\n",
    "                    average_humidity_before = np.nan\n",
    "                # get wind\n",
    "                try:\n",
    "                    average_wind_before = before_games[\"wind\"].mean()\n",
    "                except Exception:\n",
    "                    average_wind_before = np.nan\n",
    "                try:\n",
    "                    most_common_surface = before_games[\"surface\"].mode().iloc[0]  # get surface\n",
    "                except Exception:\n",
    "                    most_common_surface = np.nan\n",
    "                try:\n",
    "                    most_common_roof = before_games[\"roof\"].mode().iloc[0] # get roof\n",
    "                except Exception:\n",
    "                    most_common_roof = np.nan\n",
    "\n",
    "                ##### snap workload\n",
    "                average_snaps_before = before_games['snap_count'].mean() # get snap count\n",
    "\n",
    "                ##### travel data\n",
    "                travel_magnitude_numeric = pd.to_numeric(before_games['travel_magnitude'], errors='coerce')\n",
    "                tz_diff_numeric = pd.to_numeric(before_games['tz_diff_magnitude'], errors='coerce')\n",
    "                elevation_diff_numeric = pd.to_numeric(before_games['elevation_difference_abs_m'], errors='coerce')\n",
    "\n",
    "                sum_travel_magnitude = travel_magnitude_numeric.sum()\n",
    "                sum_tz_diff_magnitude = tz_diff_numeric.abs().sum()  # Already numeric\n",
    "                sum_elevation_difference = elevation_diff_numeric.sum()\n",
    "\n",
    "                ###################### previous game ######################\n",
    "                ##### environment data\n",
    "                try:\n",
    "                    prev_weather = prev_game[\"temperature\"]\n",
    "                except Exception:\n",
    "                    prev_weather = np.nan\n",
    "                # get humidity\n",
    "                try:\n",
    "                    prev_humidity = prev_game[\"humidity\"]\n",
    "                except Exception:\n",
    "                    prev_humidity = np.nan\n",
    "                # get wind\n",
    "                try:\n",
    "                    prev_wind = prev_game[\"wind\"]\n",
    "                except Exception:\n",
    "                    prev_wind = np.nan\n",
    "                prev_surface = prev_game[\"surface\"]  # get surface\n",
    "                prev_roof = prev_game[\"roof\"] # get roof\n",
    "\n",
    "                ##### snap workload\n",
    "                prev_snaps = prev_game['snap_count'] # get snap count\n",
    "\n",
    "                ##### travel data\n",
    "                prev_travel_magnitude = prev_game['travel_magnitude']\n",
    "                prev_elevation_difference = prev_game['elevation_difference_abs_m']\n",
    "                prev_travel_direction = prev_game['travel_direction']\n",
    "                prev_elevation_difference_abs_m = prev_game['elevation_difference_abs_m']\n",
    "                prev_is_international = prev_game[\"is_international\"]\n",
    "\n",
    "                prev_game_content = [prev_weather,prev_humidity,prev_wind,prev_surface,prev_roof,\n",
    "                                        prev_snaps,\n",
    "                                        prev_travel_magnitude,prev_is_international,prev_elevation_difference,prev_travel_direction,prev_elevation_difference_abs_m]\n",
    "\n",
    "            else:\n",
    "                average_weather_before = np.nan\n",
    "                average_humidity_before = np.nan\n",
    "                average_wind_before = np.nan\n",
    "                most_common_surface = np.nan\n",
    "                most_common_roof = np.nan\n",
    "\n",
    "                average_snaps_before = np.nan\n",
    "\n",
    "                sum_travel_magnitude = np.nan\n",
    "                sum_elevation_difference = np.nan\n",
    "                sum_tz_diff_magnitude = np.nan\n",
    "\n",
    "                prev_game_content = [np.nan,np.nan,np.nan,np.nan,np.nan,\n",
    "                                        np.nan,\n",
    "                                        np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "\n",
    "            before_content = [average_weather_before, average_humidity_before, average_wind_before, most_common_surface, most_common_roof,\n",
    "                                average_snaps_before,\n",
    "                                sum_travel_magnitude, sum_tz_diff_magnitude, sum_elevation_difference]\n",
    "            # print(before_content)\n",
    "\n",
    "            if len(after_games) > 0:\n",
    "                after_content = []\n",
    "\n",
    "                for col in production_cols:\n",
    "                    clean_series = pd.to_numeric(after_games[col], errors='coerce')\n",
    "                    after_content.append(clean_series.mean())\n",
    "                # print(len(after_content))\n",
    "\n",
    "            else:\n",
    "                for x in range(107):\n",
    "                    after_content.append(np.nan)\n",
    "\n",
    "            # print(after_content)\n",
    "\n",
    "            ##### create total row\n",
    "\n",
    "            row_to_write = group_row + before_content + prev_game_content + after_content\n",
    "            # print(row_to_write)\n",
    "\n",
    "            ##### write the row\n",
    "            with open('clean_data/agged_data2.csv', 'a', newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row_to_write)\n",
    "                \n",
    "        # break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda472f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Trey Taylor... 1/6020\n",
      "Processing Trey Washington... 2/6020\n",
      "Processing Treylon Burks... 3/6020\n",
      "Processing Treyton Welch... 4/6020\n",
      "Processing Treyvon Hester... 5/6020\n",
      "Processing Trikweze Bridges... 6/6020\n",
      "Processing Trill Williams... 7/6020\n",
      "Processing Trinity Benson... 8/6020\n",
      "Processing Trishton Jackson... 9/6020\n",
      "Processing Tristan Vizcaino... 10/6020\n",
      "Processing Tristan Wirfs... 11/6020\n",
      "Processing Tristin McCollum... 12/6020\n",
      "Processing Trovon Reed... 13/6020\n",
      "Processing Troy Andersen... 14/6020\n",
      "Processing Troy Apke... 15/6020\n",
      "Processing Troy Dye... 16/6020\n",
      "Processing Troy Fautanu... 17/6020\n",
      "Processing Troy Franklin... 18/6020\n",
      "Processing Troy Fumagalli... 19/6020\n",
      "Processing Troy Hairston... 20/6020\n",
      "Processing Troy Hill... 21/6020\n",
      "Processing Troy Niklas... 22/6020\n",
      "Processing Troy Pride... 23/6020\n",
      "Processing Troy Pride Jr.... 24/6020\n",
      "Processing Troy Reeder... 25/6020\n",
      "Processing Troymaine Pope... 26/6020\n",
      "Processing Trumaine Johnson... 27/6020\n",
      "Processing Truman Jones... 28/6020\n",
      "Processing Trystan Colon... 29/6020\n",
      "Processing Trysten Hill... 30/6020\n",
      "Processing Tua Tagovailoa... 31/6020\n",
      "Processing Tucker Addington... 32/6020\n",
      "Processing Tucker Fisk... 33/6020\n",
      "Processing Tucker Kraft... 34/6020\n",
      "Processing Tuf Borland... 35/6020\n",
      "Processing Tuli Tuipulotu... 36/6020\n",
      "Processing Tutu Atwell... 37/6020\n",
      "Processing Tuzar Skipper... 38/6020\n",
      "Processing Ty Chandler... 39/6020\n",
      "Processing Ty Hamilton... 40/6020\n",
      "Processing Ty Johnson... 41/6020\n",
      "Processing Ty Long... 42/6020\n",
      "Processing Ty Montgomery... 43/6020\n",
      "Processing Ty Nsekhe... 44/6020\n",
      "Processing Ty Okada... 45/6020\n",
      "Processing Ty Robinson... 46/6020\n",
      "Processing Ty Sambrailo... 47/6020\n",
      "Processing Ty Shelby... 48/6020\n",
      "Processing Ty Summers... 49/6020\n",
      "Processing Ty Zentner... 50/6020\n",
      "Processing Ty'Ron Hopper... 51/6020\n",
      "Processing Ty'Son Williams... 52/6020\n",
      "Processing Tycen Anderson... 53/6020\n",
      "Processing Tye Smith... 54/6020\n",
      "Processing Tyeler Davison... 55/6020\n",
      "Processing Tyjae Spears... 56/6020\n",
      "Processing Tykee Smith... 57/6020\n",
      "Processing Tylan Grable... 58/6020\n",
      "Processing Tylan Wallace... 59/6020\n",
      "Processing Tyleik Williams... 60/6020\n",
      "Processing Tyler Allgeier... 61/6020\n",
      "Processing Tyler Badie... 62/6020\n",
      "Processing Tyler Baron... 63/6020\n",
      "Processing Tyler Bass... 64/6020\n",
      "Processing Tyler Batty... 65/6020\n",
      "Processing Tyler Biadasz... 66/6020\n",
      "Processing Tyler Booker... 67/6020\n",
      "Processing Tyler Boyd... 68/6020\n",
      "Processing Tyler Bray... 69/6020\n",
      "Processing Tyler Catalina... 70/6020\n",
      "Processing Tyler Conklin... 71/6020\n",
      "Processing Tyler Coyle... 72/6020\n",
      "Processing Tyler Davis... 73/6020\n",
      "Processing Tyler Eifert... 74/6020\n",
      "Processing Tyler Ervin... 75/6020\n",
      "Processing Tyler Goodson... 76/6020\n",
      "Processing Tyler Guyton... 77/6020\n",
      "Processing Tyler Hall... 78/6020\n",
      "Processing Tyler Higbee... 79/6020\n",
      "Processing Tyler Huntley... 80/6020\n",
      "Processing Tyler Johnson... 81/6020\n",
      "Processing Tyler Kroft... 82/6020\n",
      "Processing Tyler Lacy... 83/6020\n",
      "Processing Tyler Lancaster... 84/6020\n",
      "Processing Tyler Larsen... 85/6020\n",
      "Processing Tyler Linderbaum... 86/6020\n",
      "Processing Tyler Lockett... 87/6020\n",
      "Processing Tyler Loop... 88/6020\n",
      "Processing Tyler Mabry... 89/6020\n",
      "Processing Tyler Matakevich... 90/6020\n",
      "Processing Tyler Nubin... 91/6020\n",
      "Processing Tyler Ott... 92/6020\n",
      "Processing Tyler Owens... 93/6020\n",
      "Processing Tyler Patmon... 94/6020\n",
      "Processing Tyler Scott... 95/6020\n",
      "Processing Tyler Shatley... 96/6020\n",
      "Processing Tyler Shelvin... 97/6020\n",
      "Processing Tyler Shough... 98/6020\n",
      "Processing Tyler Smith... 99/6020\n",
      "Processing Tyler Steen... 100/6020\n",
      "Processing Tyler Vrabel... 101/6020\n",
      "Processing Tyler Warren... 102/6020\n",
      "Processing Tyquan Lewis... 103/6020\n",
      "Processing Tyquan Thornton... 104/6020\n",
      "Processing Tyrann Mathieu... 105/6020\n",
      "Processing Tyre Phillips... 106/6020\n",
      "Processing Tyree Gillespie... 107/6020\n",
      "Processing Tyree Jackson... 108/6020\n",
      "Processing Tyree St. Louis... 109/6020\n",
      "Processing Tyree Wilson... 110/6020\n",
      "Processing Tyreek Burwell... 111/6020\n",
      "Processing Tyreek Hill... 112/6020\n",
      "Processing Tyreek Maddox-Williams... 113/6020\n",
      "Processing Tyreik McAllister... 114/6020\n",
      "Processing Tyrek Funderburk... 115/6020\n",
      "Processing Tyreke Smith... 116/6020\n",
      "Processing Tyrel Dodson... 117/6020\n",
      "Processing Tyrell Adams... 118/6020\n",
      "Processing Tyrell Crosby... 119/6020\n",
      "Processing Tyrell Shavers... 120/6020\n",
      "Processing Tyrell Williams... 121/6020\n",
      "Processing Tyreque Jones... 122/6020\n",
      "Processing Tyrese Robinson... 123/6020\n",
      "Processing Tyrice Knight... 124/6020\n",
      "Processing Tyrie Cleveland... 125/6020\n",
      "Processing Tyrion Davis-Price... 126/6020\n",
      "Processing Tyrion Ingram-Dawkins... 127/6020\n",
      "Processing Tyrique Jarrett... 128/6020\n",
      "Processing Tyrique Stevenson... 129/6020\n",
      "Processing Tyrod Taylor... 130/6020\n",
      "Processing Tyron Johnson... 131/6020\n",
      "Processing Tyron Smith... 132/6020\n",
      "Processing Tyrone Crawford... 133/6020\n",
      "Processing Tyrone Holmes... 134/6020\n",
      "Processing Tyrone Swoopes... 135/6020\n",
      "Processing Tyrone Tracy Jr.... 136/6020\n",
      "Processing Tyrone Wheatley Jr.... 137/6020\n",
      "Processing Tyrunn Walker... 138/6020\n",
      "Processing Tyrus Wheat... 139/6020\n",
      "Processing Tyshun Render... 140/6020\n",
      "Processing Tyson Alualu... 141/6020\n",
      "Processing Tyson Bagent... 142/6020\n",
      "Processing Tyson Campbell... 143/6020\n",
      "Processing Tyson Jackson... 144/6020\n",
      "Processing Tytus Howard... 145/6020\n",
      "Processing Tyus Bowser... 146/6020\n",
      "Processing Tyvis Powell... 147/6020\n",
      "Processing Tyvon Branch... 148/6020\n",
      "Processing Uchenna Nwosu... 149/6020\n",
      "Processing Ufomba Kamalu... 150/6020\n",
      "Processing Ugo Amadi... 151/6020\n",
      "Processing Ukeme Eligwe... 152/6020\n",
      "Processing Ulrick John... 153/6020\n",
      "Processing Ulysees Gilbert... 154/6020\n",
      "Processing Ulysses Bentley... 155/6020\n",
      "Processing Upton Stout... 156/6020\n",
      "Processing Vadal Alexander... 157/6020\n",
      "Processing Valentino Blake... 158/6020\n",
      "Processing Van Jefferson... 159/6020\n",
      "Processing Vance McDonald... 160/6020\n",
      "Processing Vederian Lowe... 161/6020\n",
      "Processing Velus Jones Jr.... 162/6020\n",
      "Processing Ventell Bryant... 163/6020\n",
      "Processing Ventrell Miller... 164/6020\n",
      "Processing Vernon Broughton... 165/6020\n",
      "Processing Vernon Butler... 166/6020\n",
      "Processing Vernon Davis... 167/6020\n",
      "Processing Vernon Hargreaves III... 168/6020\n",
      "Processing Vernon Scott... 169/6020\n",
      "Processing Verone McKinley... 170/6020\n",
      "Processing Vershon Lee... 171/6020\n",
      "Processing Vi Jones... 172/6020\n",
      "Processing Vic Beasley... 173/6020\n",
      "Processing Victor Bolden... 174/6020\n",
      "Processing Victor Cruz... 175/6020\n",
      "Processing Victor Dimukeje... 176/6020\n",
      "Processing Victor Ochi... 177/6020\n",
      "Processing Viliami Fehoko Jr.... 178/6020\n",
      "Processing Vince Biegel... 179/6020\n",
      "Processing Vince Mayle... 180/6020\n",
      "Processing Vince Wilfork... 181/6020\n",
      "Processing Vince Williams... 182/6020\n",
      "Processing Vincent Gray... 183/6020\n",
      "Processing Vincent Jackson... 184/6020\n",
      "Processing Vincent Rey... 185/6020\n",
      "Processing Vincent Taylor... 186/6020\n",
      "Processing Vincent Valentine... 187/6020\n",
      "Processing Vinnie Sunseri... 188/6020\n",
      "Processing Vinny Curry... 189/6020\n",
      "Processing Vinston Painter... 190/6020\n",
      "Processing Virgil Green... 191/6020\n",
      "Processing Vita Vea... 192/6020\n",
      "Processing Vlad Ducasse... 193/6020\n",
      "Processing Vladimir Ducasse... 194/6020\n",
      "Processing Von Miller... 195/6020\n",
      "Processing Vonn Bell... 196/6020\n",
      "Processing Vontae Davis... 197/6020\n",
      "Processing Vontarrius Dora... 198/6020\n",
      "Processing Vontaze Burfict... 199/6020\n",
      "Processing Vyncint Smith... 200/6020\n",
      "Processing Walker Little... 201/6020\n",
      "Processing Wallace Gilberry... 202/6020\n",
      "Processing Walt Aikens... 203/6020\n",
      "Processing Walt Powell... 204/6020\n",
      "Processing Walter Nolen... 205/6020\n",
      "Processing Walter Palmore... 206/6020\n",
      "Processing Walter Rouse... 207/6020\n",
      "Processing Wan'Dale Robinson... 208/6020\n",
      "Processing Wanya Morris... 209/6020\n",
      "Processing Warren Brinson... 210/6020\n",
      "Processing Warren McClendon... 211/6020\n",
      "Processing Wayne Gallman... 212/6020\n",
      "Processing Wendall Williams... 213/6020\n",
      "Processing Wendell Smallwood... 214/6020\n",
      "Processing Wes Hills... 215/6020\n",
      "Processing Wes Horton... 216/6020\n",
      "Processing Wes Martin... 217/6020\n",
      "Processing Wes Schweitzer... 218/6020\n",
      "Processing Wesley French... 219/6020\n",
      "Processing Wesley Johnson... 220/6020\n",
      "Processing Wesley Woodyard... 221/6020\n",
      "Processing Weston Richburg... 222/6020\n",
      "Processing Whitney Mercilus... 223/6020\n",
      "Processing Wil Lutz... 224/6020\n",
      "Processing Will Anderson... 225/6020\n",
      "Processing Will Anderson Jr.... 226/6020\n",
      "Processing Will Beatty... 227/6020\n",
      "Processing Will Blackmon... 228/6020\n",
      "Processing Will Campbell... 229/6020\n",
      "Processing Will Clapp... 230/6020\n",
      "Processing Will Clarke... 231/6020\n",
      "Processing Will Compton... 232/6020\n",
      "Processing Will Davis... 233/6020\n",
      "Processing Will Dissly... 234/6020\n",
      "Processing Will Fries... 235/6020\n",
      "Processing Will Fuller... 236/6020\n",
      "Processing Will Grier... 237/6020\n",
      "Processing Will Harris... 238/6020\n",
      "Processing Will Hernandez... 239/6020\n",
      "Processing Will Holden... 240/6020\n",
      "Processing Will Howard... 241/6020\n",
      "Processing Will Johnson... 242/6020\n",
      "Processing Will Levis... 243/6020\n",
      "Processing Will Mallory... 244/6020\n",
      "Processing Will McDonald... 245/6020\n",
      "Processing Will McDonald IV... 246/6020\n",
      "Processing Will Parks... 247/6020\n",
      "Processing Will Putnam... 248/6020\n",
      "Processing Will Redmond... 249/6020\n",
      "Processing Will Reichard... 250/6020\n",
      "Processing Will Richardson... 251/6020\n",
      "Processing Will Shipley... 252/6020\n",
      "Processing Will Sutton... 253/6020\n",
      "Processing Will Tukuafu... 254/6020\n",
      "Processing Will Tye... 255/6020\n",
      "Processing William Beatty... 256/6020\n",
      "Processing William Bradley-King... 257/6020\n",
      "Processing William Compton... 258/6020\n",
      "Processing William Gay... 259/6020\n",
      "Processing William Gholston... 260/6020\n",
      "Processing William Hayes... 261/6020\n",
      "Processing William Jackson... 262/6020\n",
      "Processing William Jackson III... 263/6020\n",
      "Processing William Kwenkeu... 264/6020\n",
      "Processing William Sherman... 265/6020\n",
      "Processing William Wagner... 266/6020\n",
      "Processing Willie Beavers... 267/6020\n",
      "Processing Willie Gay Jr.... 268/6020\n",
      "Processing Willie Harvey... 269/6020\n",
      "Processing Willie Henry... 270/6020\n",
      "Processing Willie Lampkin... 271/6020\n",
      "Processing Willie Snead... 272/6020\n",
      "Processing Willie Young... 273/6020\n",
      "Processing Winston Guy... 274/6020\n",
      "Processing Winston Reid... 275/6020\n",
      "Processing Woodrow Hamilton... 276/6020\n",
      "Processing Woody Marks... 277/6020\n",
      "Processing Wyatt Davis... 278/6020\n",
      "Processing Wyatt Milum... 279/6020\n",
      "Processing Wyatt Ray... 280/6020\n",
      "Processing Wyatt Teller... 281/6020\n",
      "Processing Wynton McManis... 282/6020\n",
      "Processing Xavien Howard... 283/6020\n",
      "Processing Xavier Cooper... 284/6020\n",
      "Processing Xavier Crawford... 285/6020\n",
      "Processing Xavier Gipson... 286/6020\n",
      "Processing Xavier Grimble... 287/6020\n",
      "Processing Xavier Hutchinson... 288/6020\n",
      "Processing Xavier Jones... 289/6020\n",
      "Processing Xavier Legette... 290/6020\n",
      "Processing Xavier McKinney... 291/6020\n",
      "Processing Xavier Newman-Johnson... 292/6020\n",
      "Processing Xavier Restrepo... 293/6020\n",
      "Processing Xavier Rhodes... 294/6020\n",
      "Processing Xavier Smith... 295/6020\n",
      "Processing Xavier Su'a-Filo... 296/6020\n",
      "Processing Xavier Thomas... 297/6020\n",
      "Processing Xavier Truss... 298/6020\n",
      "Processing Xavier Watts... 299/6020\n",
      "Processing Xavier Weaver... 300/6020\n",
      "Processing Xavier Williams... 301/6020\n",
      "Processing Xavier Woods... 302/6020\n",
      "Processing Xavier Woodson-Luster... 303/6020\n",
      "Processing Xavier Worthy... 304/6020\n",
      "Processing Xazavian Valladay... 305/6020\n",
      "Processing YaYa Diaby... 306/6020\n",
      "Processing Yahya Black... 307/6020\n",
      "Processing Yannick Ngakoue... 308/6020\n",
      "Processing Yasir Abdullah... 309/6020\n",
      "Processing Yasir Durant... 310/6020\n",
      "Processing Yaya Diaby... 311/6020\n",
      "Processing Yetur Gross-Matos... 312/6020\n",
      "Processing Yodny Cajuste... 313/6020\n",
      "Processing Yosh Nijman... 314/6020\n",
      "Processing Younghoe Koo... 315/6020\n",
      "Processing Za'Darius Smith... 316/6020\n",
      "Processing Zac Kerin... 317/6020\n",
      "Processing Zacch Pickens... 318/6020\n",
      "Processing Zach Allen... 319/6020\n",
      "Processing Zach Banner... 320/6020\n",
      "Processing Zach Brown... 321/6020\n",
      "Processing Zach Charbonnet... 322/6020\n",
      "Processing Zach Cunningham... 323/6020\n",
      "Processing Zach Davidson... 324/6020\n",
      "Processing Zach Ertz... 325/6020\n",
      "Processing Zach Evans... 326/6020\n",
      "Processing Zach Frazier... 327/6020\n",
      "Processing Zach Fulton... 328/6020\n",
      "Processing Zach Gentry... 329/6020\n",
      "Processing Zach Harrison... 330/6020\n",
      "Processing Zach Horton... 331/6020\n",
      "Processing Zach Kerr... 332/6020\n",
      "Processing Zach Line... 333/6020\n",
      "Processing Zach Mettenberger... 334/6020\n",
      "Processing Zach Miller... 335/6020\n",
      "Processing Zach Moore... 336/6020\n",
      "Processing Zach Orr... 337/6020\n",
      "Processing Zach Pascal... 338/6020\n",
      "Processing Zach Sieler... 339/6020\n",
      "Processing Zach Sterup... 340/6020\n",
      "Processing Zach Strief... 341/6020\n",
      "Processing Zach Tom... 342/6020\n",
      "Processing Zach Triner... 343/6020\n",
      "Processing Zach VanValkenburg... 344/6020\n",
      "Processing Zach Vigil... 345/6020\n",
      "Processing Zach Wilson... 346/6020\n",
      "Processing Zach Wood... 347/6020\n",
      "Processing Zach Zenner... 348/6020\n",
      "Processing Zachary Carter... 349/6020\n",
      "Processing Zachary Thomas... 350/6020\n",
      "Processing Zack Bailey... 351/6020\n",
      "Processing Zack Baun... 352/6020\n",
      "Processing Zack Johnson... 353/6020\n",
      "Processing Zack Kuntz... 354/6020\n",
      "Processing Zack Martin... 355/6020\n",
      "Processing Zack Moss... 356/6020\n",
      "Processing Zack Sanchez... 357/6020\n",
      "Processing Zaire Anderson... 358/6020\n",
      "Processing Zaire Barnes... 359/6020\n",
      "Processing Zaire Franklin... 360/6020\n",
      "Processing Zaire Mitchell-Paden... 361/6020\n",
      "Processing Zak DeOssie... 362/6020\n",
      "Processing Zak Zinter... 363/6020\n",
      "Processing Zamir White... 364/6020\n",
      "Processing Zander Horvath... 365/6020\n",
      "Processing Zane Beadles... 366/6020\n",
      "Processing Zane Gonzalez... 367/6020\n",
      "Processing Zaven Collins... 368/6020\n",
      "Processing Zaviar Gooden... 369/6020\n",
      "Processing Zavier Scott... 370/6020\n",
      "Processing Zay Flowers... 371/6020\n",
      "Processing Zay Jones... 372/6020\n",
      "Processing Zayne Anderson... 373/6020\n",
      "Processing Zech McPhearson... 374/6020\n",
      "Processing Zeek Biggers... 375/6020\n",
      "Processing Zeke Turner... 376/6020\n",
      "Processing Ziggy Hood... 377/6020\n",
      "Processing Zion Childress... 378/6020\n",
      "Processing Zion Johnson... 379/6020\n",
      "Processing Zion Logue... 380/6020\n",
      "Processing Zonovan Knight... 381/6020\n",
      "Processing Zyon Gilbert... 382/6020\n",
      "Processing Zyon McCollum... 383/6020\n"
     ]
    }
   ],
   "source": [
    "aggregate_data(finish_the_rest)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
